{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "from tqdm import tqdm\n",
    "from src.utils.misc import read_config\n",
    "from src.slot_attention import UOD\n",
    "from src.data.builder import build_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images = h5py.File(\"/home/cse/btech/cs1210561/scratch/CLEVRTEX_new/train.hdf5\", \"r\")\n",
    "train_images = train_images['images'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CLEVRTEXDataset(Dataset):\n",
    "    def __init__(self, image_folder = \"/home/cse/btech/cs1210561/scratch/CLEVRTEX_new/train.hdf5\", image_size = 224):\n",
    "        self.image_folder = image_folder\n",
    "        self.train_images = h5py.File(image_folder, \"r\")\n",
    "        self.train_images = self.train_images['images'][:]\n",
    "        self.val_transform_image = transforms.Compose([\n",
    "                               transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).unsqueeze(-1).unsqueeze(-1)\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_images)    \n",
    "    \n",
    "    def unormalize(self, images):\n",
    "        images = images*self.std.to(images.device)\n",
    "        images = images + self.mean.to(images.device)\n",
    "        return images         \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.train_images[idx]\n",
    "        image = image.astype('float32') / 255.0\n",
    "        image = torch.tensor(image).permute(2, 0, 1)\n",
    "        image = self.val_transform_image(image)\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CLEVRTExDataset_Old(Dataset):\n",
    "    def __init__(self, image_folder, image_size = 224):\n",
    "        self.image_folder = image_folder\n",
    "        self.image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg'))]\n",
    "        self.val_transform_image = transforms.Compose([transforms.Resize(size = image_size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "                               transforms.CenterCrop(size = image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).unsqueeze(-1).unsqueeze(-1)\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)    \n",
    "    \n",
    "    def unormalize(self, images):\n",
    "\n",
    "        images = images*self.std.to(images.device)\n",
    "        images = images + self.mean.to(images.device)\n",
    "        return images \n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.val_transform_image(image)\n",
    "        return {'image':image, 'name':img_path.split('/')[-1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch\n",
    "dat = CLEVRTExDataset_Old(image_folder = \"/home/cse/btech/cs1210561/scratch/CLEVRTEX_new/InternImgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnew = CLEVRTEXDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/home/cse/btech/cs1210561/scratch/SA/configs/our_config.py'\n",
    "config = read_config(config_file)\n",
    "model = UOD(config)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/home/cse/btech/cs1210561/scratch/SA/output/clevr_run_res112/checkpoints/epoch_468_step_524999.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = build_dataloader(dnew, num_workers=config.num_workers, batch_size=config.train_batch_size, shuffle=True)\n",
    "pbar = tqdm(enumerate(train_dataloader), ncols = 120)\n",
    "pbar.set_postfix({\"loss\":100, \"rank:\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for i, batch in enumerate(pbar):\n",
    "    model.eval()  \n",
    "\n",
    "\n",
    "    images = batch[1]\n",
    "    inp = {\"images\": images} \n",
    "    \n",
    "    results = model(inp)\n",
    "    \n",
    "    slots = results['slots']\n",
    "    \n",
    "    for name, slot in zip(names, slots):\n",
    "        all_results.append({'name': name, 'slots': slot.cpu().detach().numpy()})\n",
    "    \n",
    "    \n",
    "    if i == 0:\n",
    "        break\n",
    "\n",
    "output_file = \"image_slots_data.pkl\"\n",
    "with open(output_file, \"wb\") as f:\n",
    "    pickle.dump(all_results, f)\n",
    "\n",
    "print(f\"Data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
